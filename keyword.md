## 用語
  
### パーセプトロン
入力に対して0か1（二進数）を出力する関数。非線形。  
重み付きの和+バイアスと閾値を比較して出力を決める。
パーセプトロンのネットワークがNANDゲートを多数含む回路をシミュレートすることに使える。  
NANDゲートの万能性（それさえあればどんな関数でも計算できるという性質）から、パーセプトロンもまた万能である。  

### シグモイドニューロン
入力に対して[0,1]を出力する関数。非線形。  
大きな数に振り切っているときはパーセプトロンと同じ振る舞いを見せるが、そうでないときに滑らかな出力をする。  

### 入力層
### 出力層
### 中間層／隠れ層
### 多層パーセプトロン／MLPs
シグモイドニューロンのこと。

### フィードフォワードニューラルネットワーク／順伝播
### 再帰型ニューラルネットワーク／RNN
### 分割問題
### MNIST
手書き数字スキャン画像と正しい分類のセットこと。  
MNISTという名称は、それがアメリカ国立標準技術研究所（NIST）によって収集および修正（Modify）された二つのデータセットから成り立っていることに由来しています。  

### コスト関数
訓練画像と比較して、どれだけ正確に分類できたかを判定する関数。

### 勾配降下法
### 確率的勾配降下法
勾配降下法を高速化したもの。  

### ミニバッチ
ランダムに選んだ訓練入力。  
確率的勾配降下法で使う。  
例えば訓練セットが60000あり、ミニバッチを10とした場合は、勾配の推定を6000倍速く行える。  
ミニバッチに対して重みとバイアスの更新をしたあとは、別の訓練データを選択して再び更新を繰り返す。  

### オンライン学習／逐次学習
ミニバッチを1で設定して学習の更新を行う。  

### ハイパーパラメータ
学習率など、学習アルゴリズムで直接選択できないもの。  

### Numpy
Pythonのライブラリ。

### プーリング層
### 畳み込み層
### 畳み込みニューラルネットワーク／CNN
### 逆伝播／バックプロパゲーション
### 過学習
### One-Hot Vector
